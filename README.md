
# Online Store Revenue Analysis

## Project Overview

This project processes and analyzes order data for an online store. The primary tasks include calculating monthly revenue, revenue generated by each product, and customer revenue analysis. The project also identifies the top 10 customers based on revenue. The analysis is performed using Python and is containerized using Docker.

## Project Structure

```
project_root/
│
├── task/
│   ├── __main__.py               # Main script to run the analysis
│   ├── order_processing.py       # Functions for processing orders
│   ├── customer_analysis.py      # Functions for analyzing customer data
│   ├── product_analysis.py       # Functions for analyzing product data
│   ├── Dockerfile                # Dockerfile for the task service
│   ├── orders.csv                # Dataset file with order data
│   └── __init__.py               # Makes the task directory a package
│
├── test/
│   ├── test.py                   # Unit tests for the project
│   ├── Dockerfile                # Dockerfile for the test service
│   └── __init__.py               # Makes the test directory a package
│
├── db_init/
│   └── init.sql                  # SQL script for initializing the MySQL database
│
├── docker-compose.yml            # Docker Compose configuration file
└── README.md                     # Project documentation
```

## Architecture

The project is structured into three main services:

1. **Task Service (`task/`)**: Contains the main logic for data processing and analysis. It includes scripts to calculate revenue metrics and identify top customers. The data is read from `orders.csv`.

2. **Test Service (`test/`)**: Contains unit tests to verify the correctness of the data processing logic. It ensures that all calculations and data transformations are accurate.

3. **Database Service (`db/`)**: Uses MySQL to manage the order data. The data is initialized using an SQL script (`init.sql`).

## Docker Configuration

The project uses Docker Compose to manage multiple services. Each service has its Dockerfile and is configured in the `docker-compose.yml` file.

### Docker Compose Services

- **task**: Builds from `task/Dockerfile` and runs the data processing tasks.
- **test**: Builds from `test/Dockerfile` and runs unit tests.
- **db**: Uses the official MySQL image to host the database.

## Bringing Up the Project

Follow these steps to bring up the project using Docker:

### 1. **Clone the Repository**

Clone the repository to your local machine:

```bash
git clone <repository-url>
cd project_root
```

### 2. **Build the Docker Images**

Use Docker Compose to build the images for all services. Run the following command in the project root:

```bash
docker-compose build
```

### 3. **Start the Services**

Start the services using Docker Compose:

```bash
docker-compose up
```

This command will:

- Initialize the MySQL database with the `orders` table and data from `orders.csv`.
- Run the data processing tasks defined in the `task` service.
- Execute the unit tests in the `test` service.

### 4. **Monitor the Output**

Monitor the terminal for output from each service. The `task` service will output the following:

- Monthly Revenue
- Product Revenue
- Customer Revenue
- Top 10 Customers

The `test` service will report the results of the unit tests.

### 5. **Access the Database (Optional)**

To directly inspect the data in the MySQL database, you can access the MySQL container:

```bash
docker exec -it <db_container_id> mysql -uuser -ppassword orders
```

Replace `<db_container_id>` with your database container's ID or name. Once inside, you can run SQL queries to explore the data.

### 6. **Shut Down the Services**

To stop the services, use:

```bash
docker-compose down
```

This command stops and removes the containers, networks, and volumes created by Docker Compose.

## Additional Information

- **Error Handling**: Ensure that your system has the necessary network access and resources to build and run Docker containers. If you encounter issues during `pip install`, check for network configurations or proxy settings.

- **Data Integrity**: The provided `orders.csv` should be correctly formatted and contain valid data to avoid processing errors.

- **Testing**: The `test` service uses Python's `unittest` framework to validate the data processing logic. Make sure all tests pass to ensure the correctness of your analysis.

For further questions or contributions, please refer to the project's GitHub repository or contact the maintainer.
